{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下载数据集，项目数据集来自Kaggle，[Dogs vs. Cats Redux](https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition/data)\n",
    "\n",
    "使用kaggle-api下载：kaggle competitions download -c dogs-vs-cats-redux-kernels-edition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "if not os.path.isdir('train'):\n",
    "    if os.path.isfile('train.zip'):\n",
    "        os.system('unzip train.zip')\n",
    "    else:\n",
    "        print('FILES (train.zip) NOT FOUND, DOWNLOAD FIRST')\n",
    "\n",
    "if not os.path.isdir('test'):\n",
    "    if os.path.isfile('test.zip'):\n",
    "        os.system('unzip test.zip')\n",
    "    else:\n",
    "        print('FILES (test.zip) NOT FOUND, DOWNLOAD FIRST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "dogs=[]\n",
    "cats=[]\n",
    "\n",
    "for file in os.listdir('train'):\n",
    "    if (file.split(sep='.')[0]=='cat'):\n",
    "        cats=np.append(cats,file)\n",
    "    else:\n",
    "        dogs=np.append(dogs,file)\n",
    "\n",
    "cat_lable=np.zeros(len(cats))\n",
    "dog_lable=np.zeros(len(dogs))+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 异常值处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.applications import *\n",
    "from keras.preprocessing.image import *\n",
    "\n",
    "\n",
    "dogs_class = [\n",
    " 'n02085620','n02085782','n02085936','n02086079'\n",
    ",'n02086240','n02086646','n02086910','n02087046'\n",
    ",'n02087394','n02088094','n02088238','n02088364'\n",
    ",'n02088466','n02088632','n02089078','n02089867'\n",
    ",'n02089973','n02090379','n02090622','n02090721'\n",
    ",'n02091032','n02091134','n02091244','n02091467'\n",
    ",'n02091635','n02091831','n02092002','n02092339'\n",
    ",'n02093256','n02093428','n02093647','n02093754'\n",
    ",'n02093859','n02093991','n02094114','n02094258'\n",
    ",'n02094433','n02095314','n02095570','n02095889'\n",
    ",'n02096051','n02096177','n02096294','n02096437'\n",
    ",'n02096585','n02097047','n02097130','n02097209'\n",
    ",'n02097298','n02097474','n02097658','n02098105'\n",
    ",'n02098286','n02098413','n02099267','n02099429'\n",
    ",'n02099601','n02099712','n02099849','n02100236'\n",
    ",'n02100583','n02100735','n02100877','n02101006'\n",
    ",'n02101388','n02101556','n02102040','n02102177'\n",
    ",'n02102318','n02102480','n02102973','n02104029'\n",
    ",'n02104365','n02105056','n02105162','n02105251'\n",
    ",'n02105412','n02105505','n02105641','n02105855'\n",
    ",'n02106030','n02106166','n02106382','n02106550'\n",
    ",'n02106662','n02107142','n02107312','n02107574'\n",
    ",'n02107683','n02107908','n02108000','n02108089'\n",
    ",'n02108422','n02108551','n02108915','n02109047'\n",
    ",'n02109525','n02109961','n02110063','n02110185'\n",
    ",'n02110341','n02110627','n02110806','n02110958'\n",
    ",'n02111129','n02111277','n02111500','n02111889'\n",
    ",'n02112018','n02112137','n02112350','n02112706'\n",
    ",'n02113023','n02113186','n02113624','n02113712'\n",
    ",'n02113799','n02113978']\n",
    "\n",
    "cats_class =[\n",
    "'n02123045','n02123159','n02123394','n02123597'\n",
    ",'n02124075','n02125311','n02127052']\n",
    "\n",
    "model_ResNet50={'name':ResNet50,'shape':(224,224),'preprocess':None}\n",
    "model_VGG16={'name':VGG16,'shape':(224,224),'preprocess':None}\n",
    "model_VGG19={'name':VGG19,'shape':(224,224),'preprocess':None}\n",
    "model_InceptionV3={'name':InceptionV3,'shape':(299,299),'preprocess':inception_v3.preprocess_input}\n",
    "model_Xception={'name':Xception,'shape':(299,299),'preprocess':xception.preprocess_input}\n",
    "model_InceptionResNetV2={'name':InceptionResNetV2,'shape':(299,299),'preprocess':inception_resnet_v2.preprocess_input}\n",
    "\n",
    "\n",
    "dogs=[]\n",
    "cats=[]\n",
    "\n",
    "for file in os.listdir(r'E:\\project-py\\dog_cat\\train'):\n",
    "    if (file.split(sep='.')[0]=='cat'):\n",
    "        cats=np.append(cats,file)\n",
    "    else:\n",
    "        dogs=np.append(dogs,file)\n",
    "\n",
    "\n",
    "\n",
    "def check_err_picture(model,model_shape,preprocess_input,picture_names,correct_class):    \n",
    "    bad_pict=[]\n",
    "    \n",
    "    for file in picture_names:\n",
    "        img = load_img(r'E:\\project-py\\dog_cat\\train\\\\'+file, target_size=model_shape)\n",
    "        x = img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        if preprocess_input:\n",
    "            x = preprocess_input(x)\n",
    "        \n",
    "        preds = model.predict(x)\n",
    "        pred_class=densenet.decode_predictions(preds, top=20)[0]\n",
    "        \n",
    "        check_class=[(lambda x:x[0])(x) for x in pred_class]\n",
    "        #print(check_class)\n",
    "        \n",
    "        status=False\n",
    "        for d in check_class:\n",
    "            if d in correct_class:\n",
    "                status=True\n",
    "                break\n",
    "        \n",
    "        if not status:\n",
    "            print(file,pred_class)\n",
    "            bad_pict.append(file)\n",
    "        \n",
    "    return bad_pict\n",
    "        \n",
    "\n",
    "def check_error_pict(model_name):\n",
    "    err_list=[]\n",
    "    model = model_name['name'](weights='imagenet')\n",
    "    shape = model_name['shape']\n",
    "    preprocess_input=model_name['preprocess']\n",
    "    \n",
    "    dog_err=check_err_picture(model,shape,preprocess_input,dogs,dogs_class)\n",
    "    cat_err=check_err_picture(model,shape,preprocess_input,cats,cats_class)\n",
    "    err_list.append(dog_err)\n",
    "    err_list.append(cat_err)\n",
    "    return err_list        \n",
    "\n",
    "err_ResNet50=check_error_pict(model_ResNet50)\n",
    "#err_VGG16=check_error_pict(model_VGG16)\n",
    "#err_VGG19=check_error_pict(model_VGG19)\n",
    "\n",
    "#all_err=list( set(err_ResNet50).intersection(set(err_VGG16)).intersection(set(err_VGG19)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 划分验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "dogs_train,dogs_valid,dog_lable_train,dog_lable_valid=train_test_split(dogs,dog_lable,test_size=0.2,random_state=10,shuffle=True)\n",
    "cats_train,cats_valid,dog_lable_train,dog_lable_valid=train_test_split(cats,dog_lable,test_size=0.2,random_state=10,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('train2'):\n",
    "    shutil.rmtree('train2')\n",
    "    os.mkdir('train2')\n",
    "    os.mkdir(r'train2/cat')\n",
    "    os.mkdir(r'train2/dog')\n",
    "else:\n",
    "    os.mkdir('train2')\n",
    "    os.mkdir(r'train2/cat')\n",
    "    os.mkdir(r'train2/dog')\n",
    "\n",
    "if os.path.exists('valid'):\n",
    "    shutil.rmtree('valid')\n",
    "    os.mkdir('valid')\n",
    "    os.mkdir(r'valid/cat')\n",
    "    os.mkdir(r'valid/dog')\n",
    "else:\n",
    "    os.mkdir('valid')\n",
    "    os.mkdir(r'valid/cat')\n",
    "    os.mkdir(r'valid/dog')\n",
    "\n",
    "if os.path.exists('test2'):\n",
    "    shutil.rmtree('test2')\n",
    "else:\n",
    "    os.mkdir('test2')\n",
    "\n",
    "def link_image(image_name,train_valid,dog_or_cats):\n",
    "    for file in image_name:\n",
    "        if train_valid=='T':\n",
    "            if dog_or_cats =='CAT':\n",
    "                os.symlink(r'train/'+file,r'train2/cat/'+file)\n",
    "            else:\n",
    "                os.symlink(r'train/'+file,r'train2/dog/'+file)\n",
    "        else:\n",
    "            if dog_or_cats =='CAT':\n",
    "                os.symlink(r'train/'+file,r'valid/cat/'+file)\n",
    "            else:\n",
    "                os.symlink(r'train/'+file,r'valid/dog/'+file)\n",
    "\n",
    "link_image(dogs_train,'T','DOG')   \n",
    "link_image(dogs_valid,'V','DOG')    \n",
    "link_image(cats_train,'T','CAT')    \n",
    "link_image(cats_valid,'V','CAT')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for windows\n",
    "!tree\n",
    "#for linux\n",
    "#!tree -d\n",
    "\n",
    "print('\\n')\n",
    "print('statistics:')\n",
    "print('totol train pictures  :{}'.format(len(os.listdir('train'))))\n",
    "print('totol test  pictures  :{}'.format(len(os.listdir('test'))))\n",
    "print('train      set:  cats :{}'.format(len(os.listdir(r'train2/cat'))))\n",
    "print('train      set:  dogs :{}'.format(len(os.listdir(r'train2/dog'))))\n",
    "print('validation set:  cats :{}'.format(len(os.listdir(r'valid/cat'))))\n",
    "print('validation set:  dogs :{}'.format(len(os.listdir(r'valid/dog'))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 探索数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "dog_path=r'train/'+random.choice(dogs)\n",
    "cat_path=r'train/'+random.choice(cats)\n",
    "\n",
    "dog_pict=cv2.resize(cv2.imread(dog_path),(200,200))\n",
    "cat_pict=cv2.resize(cv2.imread(cat_path),(200,200))\n",
    "\n",
    "plt.figure(figsize=(10,5),dpi=90)\n",
    "p1=plt.subplot(1,2,1)\n",
    "p2=plt.subplot(1,2,2)\n",
    "p1.set_title(\"random dog\")\n",
    "p2.set_title(\"random cat\")\n",
    "p1.imshow(dog_pict)\n",
    "p2.imshow(cat_pict)\n",
    "p1.axis('off')\n",
    "p2.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.applications import *\n",
    "from keras.preprocessing.image import *\n",
    "\n",
    "'''\n",
    "input1 = Input(shape=(299, 299, 3))\n",
    "input2 = Input(shape=(224, 224, 3))\n",
    "input_set=[input1,input2]\n",
    "'''\n",
    "\n",
    "model_ResNet50={'name':ResNet50,'shape':(224,224),'preprocess':None}\n",
    "model_VGG16={'name':VGG16,'shape':(224,224),'preprocess':None}\n",
    "model_VGG19={'name':VGG19,'shape':(224,224),'preprocess':None}\n",
    "model_InceptionV3={'name':InceptionV3,'shape':(299,299),'preprocess':inception_v3.preprocess_input}\n",
    "model_Xception={'name':Xception,'shape':(299,299),'preprocess':xception.preprocess_input}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_model(model_input,model_dict):\n",
    "    if model_dict['preprocess']:\n",
    "        x = Lambda(model_dict['preprocess'])(model_input)\n",
    "    else:\n",
    "        x=model_input\n",
    "        \n",
    "    base_model=model_dict['name'](input_tensor=x,weights='imagenet',include_top=False)\n",
    "    for layers in base_model.layers:\n",
    "        layers.trainable = False\n",
    "    return base_model\n",
    "\n",
    "def model_concatenate(input_set,model_set):\n",
    "    #input1 = Input(shape=(299, 299, 3))\n",
    "    input1=input_set[0]\n",
    "    #input2 = Input(shape=(224, 224, 3))\n",
    "    input2=input_set[1]\n",
    "\n",
    "    mid_out=[]\n",
    "    \n",
    "    for i in range(len(model_set)):\n",
    "        if model_set[i] in [model_Xception,model_InceptionV3]:\n",
    "            base_model=import_model(input1,model_set[i])\n",
    "        else:\n",
    "            base_model=import_model(input2,model_set[i])\n",
    "    \n",
    "        pool_layer=GlobalAveragePooling2D()(base_model.output)\n",
    "        mid_out.append(pool_layer)\n",
    "    \n",
    "    #print(mid_out)\n",
    "    \n",
    "    if (len(model_set)>1):\n",
    "        x= Concatenate(axis=-1)(mid_out)\n",
    "    else:\n",
    "        x=mid_out[0]\n",
    "    \n",
    "    x = Dropout(0.5)(x)\n",
    "    out=Dense(1,activation='sigmoid')(x)\n",
    "    #print(out)\n",
    "    \n",
    "    return out\n",
    "\n",
    "def input_define(mask):\n",
    "    input_tensor=[]\n",
    "    if mask[0]==1:\n",
    "        input_tensor.append(Input(shape=(299, 299, 3)))\n",
    "    if mask[1]==1:\n",
    "        input_tensor.append(Input(shape=(224, 224, 3)))\n",
    "    return input_tensor\n",
    "\n",
    "\n",
    "def img_load_mask_transfer(input_type,mask,enhance=False):\n",
    "    masked_load=[]\n",
    "    \n",
    "    # enhance parameter for train\n",
    "    if enhance:\n",
    "        if input_type=='train':\n",
    "            data_gen_args = dict(featurewise_center=True,\n",
    "                         featurewise_std_normalization=True,\n",
    "                         rotation_range=90.,\n",
    "                         width_shift_range=0.1,\n",
    "                         height_shift_range=0.1,\n",
    "                         horizontal_flip=True,\n",
    "                         vertical_flip=True,\n",
    "                         zoom_range=0.2)\n",
    "    else:\n",
    "        data_gen_args = dict()\n",
    "\n",
    "    #   directories  from different input        \n",
    "    if (input_type=='train'):\n",
    "        load_direct=r'train2'\n",
    "    elif (input_type=='valid'):\n",
    "        load_direct=r'valid'\n",
    "    elif (input_type=='test'):\n",
    "        load_direct=r'test'\n",
    "\n",
    "    #   mask  ImageDataGenerator   \n",
    "    if mask[0]==1:\n",
    "        image_size=(299,299)\n",
    "        gen1 = ImageDataGenerator(**data_gen_args)\n",
    "        image_gen1=gen1.flow_from_directory(directory=load_direct,class_mode='binary',target_size=(299, 299),batch_size=20,seed=1)\n",
    "        masked_load.append(image_gen1)\n",
    "    if mask[1]==1:\n",
    "        image_size=(224,224)\n",
    "        gen2 = ImageDataGenerator(**data_gen_args)\n",
    "        image_gen2 = gen2.flow_from_directory(directory=load_direct,class_mode='binary',target_size=(224,224),batch_size=20,seed=1)\n",
    "        masked_load.append(image_gen2)\n",
    "    # if not use append  then use zip\n",
    "    if sum(mask)>1:\n",
    "        return(zip(image_gen1,image_gen2))\n",
    "    else:\n",
    "        return masked_load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建基础模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_set=[model_ResNet50,model_Xception]\n",
    "\n",
    "##   model_mask   used for mask input(train,valid,test)\n",
    "model_mask=[0,0]\n",
    "for i in range(len(model_set)):\n",
    "    if model_set[i] in [model_Xception,model_InceptionV3]:\n",
    "        model_mask[0]=1\n",
    "    else:\n",
    "        model_mask[1]=1\n",
    "\n",
    "print(model_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_set=input_define(model_mask)\n",
    "print(input_set)\n",
    "\n",
    "out=model_concatenate(input_set,model_set)\n",
    "\n",
    "model = Model(input_set, out)\n",
    "\n",
    "model.compile(optimizer='adadelta', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_load=img_load_mask_transfer('train',model_mask,True)\n",
    "print(train_load)\n",
    "#print(train_load[0].__dict__)\n",
    "\n",
    "valid_load=img_load_mask_transfer('valid',model_mask)\n",
    "#print(valid_load)\n",
    "\n",
    "test_load=img_load_mask_transfer('test',model_mask)\n",
    "#print(test_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.fit(X_train, y_train, batch_size=128, nb_epoch=8, validation_split=0.2)\n",
    "\n",
    "train_his1 = model.fit_generator(train_load, epochs=10, validation_data=valid_load ,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型结果可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt  \n",
    "history=np.load(npy_dir_path)  \n",
    "history=history.tolist()  \n",
    "acc=history['acc']  \n",
    "loss=history['loss']  \n",
    "val_acc=history['val_acc']  \n",
    "val_loss=history['val_loss']  \n",
    "nb_epoach=np.size(acc)  \n",
    "  \n",
    "plt.xlabel('Epochs')  \n",
    "plt.ylabel('Loss')  \n",
    "plt.title('VGG-16 Loss Trend')  \n",
    "plt.plot(loss,'blue',label='Training Loss')  \n",
    "plt.plot(val_loss,'green',label='Validation Loss')  \n",
    "plt.xticks(range(0,nb_epoach))  \n",
    "plt.legend()  \n",
    "plt.show()  \n",
    "  \n",
    "plt.xlabel('Epochs')  \n",
    "plt.ylabel('Loss')  \n",
    "plt.title('VGG-16 Accuracy Trend')  \n",
    "plt.plot(acc,'blue',label='Training Loss')  \n",
    "plt.plot(val_acc,'green',label='Validation Loss')  \n",
    "plt.xticks(range(0,nb_epoach))  \n",
    "plt.legend()  \n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, layer in enumerate(model.layers):\n",
    "    print('Model name: {}'.format(model_set))\n",
    "    print('  seq        layer_name')\n",
    "    print(i, layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.visualize_util import model_to_dot, plot\n",
    "\n",
    "SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict_generator\n",
    "\n",
    "y_pred = model.predict_generator(X_test, verbose=1)\n",
    "y_pred = y_pred.clip(min=0.005, max=0.995)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
