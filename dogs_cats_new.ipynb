{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下载数据集，项目数据集来自Kaggle，[Dogs vs. Cats Redux](https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition/data)\n",
    "\n",
    "使用kaggle-api下载："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "if not os.path.isdir('train'):\n",
    "    if os.path.isfile('train.zip'):\n",
    "        os.system('unzip train.zip')\n",
    "    else:\n",
    "        print('FILES (train.zip) NOT FOUND, DOWNLOAD FIRST')\n",
    "\n",
    "if not os.path.isdir('test'):\n",
    "    if os.path.isfile('test.zip'):\n",
    "        os.system('unzip test.zip')\n",
    "    else:\n",
    "        print('FILES (test.zip) NOT FOUND, DOWNLOAD FIRST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "dogs=[]\n",
    "cats=[]\n",
    "\n",
    "for file in os.listdir('train'):\n",
    "    if (file.split(sep='.')[0]=='cat'):\n",
    "        cats=np.append(cats,file)\n",
    "    else:\n",
    "        dogs=np.append(dogs,file)\n",
    "\n",
    "cat_lable=np.zeros(len(cats))\n",
    "dog_lable=np.zeros(len(dogs))+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 划分验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs_train,dogs_valid,dog_lable_train,dog_lable_valid=train_test_split(dogs,dog_lable,test_size=0.2,random_state=10,shuffle=True)\n",
    "cats_train,cats_valid,dog_lable_train,dog_lable_valid=train_test_split(cats,dog_lable,test_size=0.2,random_state=10,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "if os.path.exists('train2'):\n",
    "    shutil.rmtree('train2')\n",
    "    os.mkdir('train2')\n",
    "    os.mkdir(r'train2/cat')\n",
    "    os.mkdir(r'train2/dog')\n",
    "else:\n",
    "    os.mkdir('train2')\n",
    "    os.mkdir(r'train2/cat')\n",
    "    os.mkdir(r'train2/dog')\n",
    "\n",
    "if os.path.exists('valid'):\n",
    "    shutil.rmtree('valid')\n",
    "    os.mkdir('valid')\n",
    "    os.mkdir(r'valid/cat')\n",
    "    os.mkdir(r'valid/dog')\n",
    "else:\n",
    "    os.mkdir('valid')\n",
    "    os.mkdir(r'valid/cat')\n",
    "    os.mkdir(r'valid/dog')\n",
    "\n",
    "if os.path.exists('test2'):\n",
    "    shutil.rmtree('test2')\n",
    "else:\n",
    "    os.mkdir('test2')\n",
    "\n",
    "def link_image(image_name,train_valid,dog_or_cats):\n",
    "    for file in image_name:\n",
    "        if train_valid=='T':\n",
    "            if dog_or_cats =='CAT':\n",
    "                os.symlink(r'train/'+file,r'train2/cat/'+file)\n",
    "            else:\n",
    "                os.symlink(r'train/'+file,r'train2/dog/'+file)\n",
    "        else:\n",
    "            if dog_or_cats =='CAT':\n",
    "                os.symlink(r'train/'+file,r'valid/cat/'+file)\n",
    "            else:\n",
    "                os.symlink(r'train/'+file,r'valid/dog/'+file)\n",
    "\n",
    "link_image(dogs_train,'T','DOG')   \n",
    "link_image(dogs_valid,'V','DOG')    \n",
    "link_image(cats_train,'T','CAT')    \n",
    "link_image(cats_valid,'V','CAT')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for windows\n",
    "!tree\n",
    "#for linux\n",
    "#!tree -d\n",
    "\n",
    "print('\\n')\n",
    "print('statistics:')\n",
    "print('totol train pictures  :{}'.format(len(os.listdir('train'))))\n",
    "print('totol test  pictures  :{}'.format(len(os.listdir('test'))))\n",
    "print('train      set:  cats :{}'.format(len(os.listdir(r'train2/cat'))))\n",
    "print('train      set:  dogs :{}'.format(len(os.listdir(r'train2/dog'))))\n",
    "print('validation set:  cats :{}'.format(len(os.listdir(r'valid/cat'))))\n",
    "print('validation set:  dogs :{}'.format(len(os.listdir(r'valid/dog'))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 探索数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "dog_path=r'train/'+random.choice(dogs)\n",
    "cat_path=r'train/'+random.choice(cats)\n",
    "\n",
    "dog_pict=cv2.resize(cv2.imread(dog_path),(200,200))\n",
    "cat_pict=cv2.resize(cv2.imread(cat_path),(200,200))\n",
    "\n",
    "plt.figure(figsize=(10,5),dpi=90)\n",
    "p1=plt.subplot(1,2,1)\n",
    "p2=plt.subplot(1,2,2)\n",
    "p1.set_title(\"random dog\")\n",
    "p2.set_title(\"random cat\")\n",
    "p1.imshow(dog_pict)\n",
    "p2.imshow(cat_pict)\n",
    "p1.axis('off')\n",
    "p2.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.applications import *\n",
    "from keras.preprocessing.image import *\n",
    "\n",
    "'''\n",
    "input1 = Input(shape=(299, 299, 3))\n",
    "input2 = Input(shape=(224, 224, 3))\n",
    "input_set=[input1,input2]\n",
    "'''\n",
    "\n",
    "model_ResNet50={'name':ResNet50,'shape':(224,224),'preprocess':None}\n",
    "model_VGG16={'name':VGG16,'shape':(224,224),'preprocess':None}\n",
    "model_VGG19={'name':VGG19,'shape':(224,224),'preprocess':None}\n",
    "model_InceptionV3={'name':InceptionV3,'shape':(299,299),'preprocess':inception_v3.preprocess_input}\n",
    "model_Xception={'name':Xception,'shape':(299,299),'preprocess':xception.preprocess_input}\n",
    "\n",
    "def import_model(model_input,model_dict):\n",
    "    if model_dict['preprocess']:\n",
    "        x = Lambda(model_dict['preprocess'])(model_input)\n",
    "    else:\n",
    "        x=model_input\n",
    "        \n",
    "    base_model=model_dict['name'](input_tensor=x,weights='imagenet',include_top=False)\n",
    "    for layers in base_model.layers:\n",
    "        layers.trainable = False\n",
    "    return base_model\n",
    "\n",
    "def model_concatenate(input_set,model_set):\n",
    "    #input1 = Input(shape=(299, 299, 3))\n",
    "    input1=input_set[0]\n",
    "    #input2 = Input(shape=(224, 224, 3))\n",
    "    input2=input_set[1]\n",
    "\n",
    "    mid_out=[]\n",
    "    \n",
    "    for i in range(len(model_set)):\n",
    "        if model_set[i] in [model_Xception,model_InceptionV3]:\n",
    "            base_model=import_model(input1,model_set[i])\n",
    "        else:\n",
    "            base_model=import_model(input2,model_set[i])\n",
    "    \n",
    "        pool_layer=GlobalAveragePooling2D()(base_model.output)\n",
    "        mid_out.append(pool_layer)\n",
    "    \n",
    "    #print(mid_out)\n",
    "    \n",
    "    if (len(model_set)>1):\n",
    "        x= Concatenate(axis=-1)(mid_out)\n",
    "    else:\n",
    "        x=mid_out[0]\n",
    "    \n",
    "    x = Dropout(0.5)(x)\n",
    "    out=Dense(1,activation='sigmoid')(x)\n",
    "    #print(out)\n",
    "    \n",
    "    return out\n",
    "\n",
    "def input_define(mask):\n",
    "    input_tensor=[]\n",
    "    if mask[0]==1:\n",
    "        input_tensor.append(Input(shape=(299, 299, 3)))\n",
    "    if mask[1]==1:\n",
    "        input_tensor.append(Input(shape=(224, 224, 3)))\n",
    "    return input_tensor\n",
    "\n",
    "\n",
    "def img_load_mask_transfer(input_type,mask,enhance=False):\n",
    "    masked_load=[]\n",
    "    \n",
    "    # enhance parameter for train\n",
    "    if enhance:\n",
    "        if input_type=='train':\n",
    "            data_gen_args = dict(featurewise_center=True,\n",
    "                         featurewise_std_normalization=True,\n",
    "                         rotation_range=90.,\n",
    "                         width_shift_range=0.1,\n",
    "                         height_shift_range=0.1,\n",
    "                         horizontal_flip=True,\n",
    "                         vertical_flip=True,\n",
    "                         zoom_range=0.2)\n",
    "    else:\n",
    "        data_gen_args = dict()\n",
    "\n",
    "    #   directories  from different input        \n",
    "    if (input_type=='train'):\n",
    "        load_direct=r'E:\\project-py\\dog_cat\\train2'\n",
    "    elif (input_type=='valid'):\n",
    "        load_direct=r'E:\\project-py\\dog_cat\\valid'\n",
    "    elif (input_type=='test'):\n",
    "        load_direct=r'E:\\project-py\\dog_cat\\test'\n",
    "\n",
    "    #   mask  ImageDataGenerator   \n",
    "    if mask[0]==1:\n",
    "        image_size=(299,299)\n",
    "        gen1 = ImageDataGenerator(**data_gen_args)\n",
    "        image_gen1=gen1.flow_from_directory(directory=load_direct,\n",
    "                                            class_mode='binary',\n",
    "                                            target_size=(299, 299),\n",
    "                                            batch_size=20,\n",
    "                                            seed=1)\n",
    "        masked_load.append(image_gen1)\n",
    "    if mask[1]==1:\n",
    "        image_size=(224,224)\n",
    "        gen2 = ImageDataGenerator(**data_gen_args)\n",
    "        image_gen2 = gen2.flow_from_directory(directory=load_direct,\n",
    "                                              class_mode='binary',\n",
    "                                              target_size=(224,224),\n",
    "                                              batch_size=20,\n",
    "                                              seed=1)\n",
    "        masked_load.append(image_gen2)\n",
    "    # if not use append  then use zip\n",
    "    if sum(mask)>1:\n",
    "        return(zip(image_gen1,image_gen2))\n",
    "    else:\n",
    "        return masked_load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建基础模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_set=[model_ResNet50,model_Xception]\n",
    "\n",
    "##   model_mask   used for mask input(train,valid,test)\n",
    "model_mask=[0,0]\n",
    "for i in range(len(model_set)):\n",
    "    if model_set[i] in [model_Xception,model_InceptionV3]:\n",
    "        model_mask[0]=1\n",
    "    else:\n",
    "        model_mask[1]=1\n",
    "\n",
    "print(model_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_set=input_define(model_mask)\n",
    "print(input_set)\n",
    "\n",
    "out=model_concatenate(input_set,model_set)\n",
    "\n",
    "model = Model(input_set, out)\n",
    "\n",
    "model.compile(optimizer='adadelta', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_load=img_load_mask_transfer('train',model_mask,True)\n",
    "print(train_load)\n",
    "#print(train_load[0].__dict__)\n",
    "\n",
    "valid_load=img_load_mask_transfer('valid',model_mask)\n",
    "#print(valid_load)\n",
    "\n",
    "test_load=img_load_mask_transfer('test',model_mask)\n",
    "#print(test_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, batch_size=128, nb_epoch=8, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, layer in enumerate(model.layers):\n",
    "    print('Model name: {}'.format(model_set))\n",
    "    print('  seq        layer_name')\n",
    "    print(i, layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.visualize_util import model_to_dot, plot\n",
    "\n",
    "SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
